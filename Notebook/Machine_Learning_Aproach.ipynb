{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c77cb45-8a86-465f-8da2-7d295f41d270",
   "metadata": {},
   "source": [
    "## ðŸ“¦ Dataset\n",
    "\n",
    "This project uses and transforms the Kaggle dataset:\n",
    "\n",
    "**Source**: [Sephora Products and Skincare Reviews by nadyinky](https://www.kaggle.com/datasets/nadyinky/sephora-products-and-skincare-reviews)  \n",
    "**License**: [Creative Commons Attribution 4.0 (CC BY 4.0)](https://creativecommons.org/licenses/by/4.0/)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a09cbe03-e1e1-4533-8b86-29e3c883e3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "172df0df-85a4-430b-87c0-e9ab69d2bf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_0_250 = pd.read_csv(r\"F:\\My_CSV_\\final_test_1\\reviews_0-250.csv\", low_memory=False)\n",
    "reviews_250_500 = pd.read_csv(r\"F:\\My_CSV_\\final_test_1\\reviews_250-500.csv\", low_memory=False)\n",
    "reviews_500_750 = pd.read_csv(r\"F:\\My_CSV_\\final_test_1\\reviews_500-750.csv\", low_memory=False)\n",
    "reviews_750_1250 = pd.read_csv(r\"F:\\My_CSV_\\final_test_1\\reviews_750-1250.csv\", low_memory=False)\n",
    "reviews_1250_end = pd.read_csv(r\"F:\\My_CSV_\\final_test_1\\reviews_1250-end.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c38d0e9-780e-43ff-85ed-1bff53b108ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_0_250_c = reviews_0_250.copy()\n",
    "reviews_250_500_c =reviews_250_500.copy()\n",
    "reviews_500_750_c =reviews_500_750.copy()\n",
    "reviews_750_1250_c = reviews_750_1250.copy()\n",
    "reviews_1250_end_C =reviews_1250_end.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e990b3-2241-43cd-a5d1-1f051a8104d4",
   "metadata": {},
   "source": [
    "## Data Cleaning: Dropping Unnecessary Columns, Creating full_review, and Removing Duplicates\n",
    "In this section, I dropped some columns, created a new column full_review by combining review_text and review_title, then cleaned the data and removed duplicate entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da4ef43f-aded-4f44-89bf-5c2e84e8baa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_preprocess_reviews(df):\n",
    "    import re\n",
    "\n",
    "    # Step 1: Drop irrelevant columns\n",
    "    columns_to_drop_initial = [\n",
    "        'Unnamed: 0', 'submission_time', 'total_feedback_count',\n",
    "        'total_pos_feedback_count', 'total_neg_feedback_count',\n",
    "        'product_name', 'author_id', 'helpfulness', 'is_recommended',\n",
    "        'brand_name', 'price_usd', 'product_id',\n",
    "        # Drop weak or noisy features\n",
    "        'eye_color', 'hair_color'\n",
    "    ]\n",
    "    df = df.drop(columns=columns_to_drop_initial, errors='ignore')\n",
    "\n",
    "    # Step 2: Fill missing review_title and review_text\n",
    "    df['review_title'] = df['review_title'].fillna('')\n",
    "    df['review_text'] = df['review_text'].fillna('')\n",
    "\n",
    "    # Step 3: Combine into full_review\n",
    "    df['full_review'] = df['review_title'] + ' ' + df['review_text']\n",
    "\n",
    "    # Step 4: Remove empty full_review rows\n",
    "    df = df[df['full_review'].str.strip() != '']\n",
    "\n",
    "    # Step 5: Drop original title/text\n",
    "    df = df.drop(columns=['review_title', 'review_text'], errors='ignore')\n",
    "\n",
    "    # Step 6: Clean full_review text\n",
    "    def clean_text_bert(text):\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        return text.strip()\n",
    "\n",
    "    df['full_review'] = df['full_review'].apply(clean_text_bert)\n",
    "\n",
    "    # ðŸ”¥ Step 7: Drop duplicate full_review texts\n",
    "    df = df.drop_duplicates(subset='full_review')\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "reviews_0_250_c = clean_and_preprocess_reviews(reviews_0_250.copy())\n",
    "reviews_250_500_c = clean_and_preprocess_reviews(reviews_250_500.copy())\n",
    "reviews_500_750_c = clean_and_preprocess_reviews(reviews_500_750.copy())\n",
    "reviews_750_1250_c = clean_and_preprocess_reviews(reviews_750_1250.copy())\n",
    "reviews_1250_end_C = clean_and_preprocess_reviews(reviews_1250_end.copy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7419989f-0383-4b5b-b030-b6b4fc46fd99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['rating', 'skin_tone', 'skin_type', 'full_review'], dtype='object')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_1250_end_C.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "441f7071-82c8-43ed-aa1a-4eed2eecff7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_0_250_clean = reviews_0_250_c.copy()\n",
    "reviews_250_500_clean =reviews_250_500_c.copy()\n",
    "reviews_500_750_clean =reviews_500_750_c.copy()\n",
    "reviews_750_1250_clean = reviews_750_1250_c.copy()\n",
    "reviews_1250_end_Clean =reviews_1250_end_C.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced853f5-f43a-455a-9acc-a69f351f9ca8",
   "metadata": {},
   "source": [
    "## Sampling and Concatenating Data\n",
    "Since we had a large dataset, I decided to randomly select 2000 samples and concatenate them together for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1466aa4e-19a8-405e-8c3c-d01745ef37a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final balanced dataset shape: (10000, 4)\n",
      "\n",
      "Perfect class distribution:\n",
      "rating\n",
      "1    0.2\n",
      "2    0.2\n",
      "3    0.2\n",
      "4    0.2\n",
      "5    0.2\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "# Suppress the specific DeprecationWarning about groupby.apply\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    category=DeprecationWarning,\n",
    "    message=\"DataFrameGroupBy.apply operated on the grouping columns\"\n",
    ")\n",
    "\n",
    "# Sample 2000 reviews from each DataFrame (with random_state for reproducibility)\n",
    "sample_0_250 = reviews_0_250_clean.sample(n=2000, random_state=42)\n",
    "sample_250_500 = reviews_250_500_clean.sample(n=2000, random_state=42)\n",
    "sample_500_750 = reviews_500_750_clean.sample(n=2000, random_state=42)\n",
    "sample_750_1250 = reviews_750_1250_clean.sample(n=2000, random_state=42)\n",
    "sample_1250_end = reviews_1250_end_Clean.sample(n=2000, random_state=42)\n",
    "\n",
    "# Combine all cleaned datasets\n",
    "all_reviews = pd.concat([\n",
    "    reviews_0_250_clean,\n",
    "    reviews_250_500_clean,\n",
    "    reviews_500_750_clean,\n",
    "    reviews_750_1250_clean,\n",
    "    reviews_1250_end_Clean\n",
    "], ignore_index=True)\n",
    "\n",
    "def sample_with_rating(df):\n",
    "    sampled = df.sample(n=min(len(df), 2000), random_state=42)\n",
    "    sampled['rating'] = df.name  # df.name is the group key (rating)\n",
    "    return sampled\n",
    "\n",
    "stratified_sample = (\n",
    "    all_reviews\n",
    "    .groupby('rating', group_keys=False)\n",
    "    .apply(sample_with_rating)  # warning suppressed above, no changes here\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Verify results\n",
    "print(\"Final balanced dataset shape:\", stratified_sample.shape)\n",
    "print(\"\\nPerfect class distribution:\")\n",
    "print(stratified_sample['rating'].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b351269-14ad-4ed6-b6c9-44fc4f789bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = stratified_sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c5e036f-c594-4314-a5ca-ad3780b38f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X.pop('rating')\n",
    "#y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5f929d6-6966-4ce6-a950-f03caa7e1254",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28fbf33d-1aaf-4cd4-8a4d-dda90970d153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef832784-a7c4-41f2-bb54-b72af448d8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8bbb3c-3e67-4b8b-bdd2-d29ff138c08b",
   "metadata": {},
   "source": [
    "## Preprocessing Pipelines Setup\n",
    "I created separate pipelines for text and categorical data: the text pipeline uses TfidfVectorizer with unigram and bigram features, while the categorical pipeline handles missing values and applies one-hot encoding. These pipelines are then combined using make_column_transformer for streamlined preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3219a9bf-e032-43d4-b996-15a4a60baf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Correct text pipeline - remove 'sparse' parameter\n",
    "text_pipe = make_pipeline(\n",
    "    TfidfVectorizer(\n",
    "        max_features=5000,       # Increased from 100\n",
    "        stop_words='english',\n",
    "        ngram_range=(1, 2),      # Using both unigrams and bigrams\n",
    "        min_df=5,                # Ignore terms appearing in <5 docs\n",
    "        max_df=0.7               # Ignore terms in >70% of docs\n",
    "    )\n",
    "    # No sparse parameter needed - it's always sparse by default\n",
    ")\n",
    "\n",
    "# Categorical pipeline\n",
    "cat_pipe = make_pipeline(\n",
    "    SimpleImputer(strategy='constant', fill_value='N_A'),\n",
    "    OneHotEncoder(handle_unknown='ignore', sparse_output=True)  # Correct parameter name\n",
    ")\n",
    "\n",
    "# Combine pipelines\n",
    "preprocessor = make_column_transformer(\n",
    "    (cat_pipe, ['skin_type', 'skin_tone']),  # Example categorical columns\n",
    "    (text_pipe, \"full_review\"),             # Text column\n",
    "    remainder='drop'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e174fd41-9ac8-4a86-8611-7046eebe3b46",
   "metadata": {},
   "source": [
    "## Model Training with XGBoost and Feature Selection\n",
    "For the regression task, I set up a pipeline combining preprocessing, Recursive Feature Elimination (RFE), and an XGBoost regressor. Hyperparameters were tuned using GridSearchCV with a custom RMSE scorer to optimize model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40223329-d69f-4a5b-8155-d6611ad93de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Best parameters: {'rfe__estimator__learning_rate': 0.059362936390648706, 'rfe__estimator__max_depth': 4, 'rfe__estimator__n_estimators': 197, 'rfe__estimator__reg_alpha': 0.3243563176277785, 'rfe__estimator__reg_lambda': 5.0229339349076065, 'rfe__n_features_to_select': 49}\n",
      "Best RMSE (negative): -1.0877509121322375\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from sklearn.feature_selection import RFE\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "\n",
    "# Custom RMSE scorer for GridSearchCV (note: GridSearchCV expects higher score = better, so we negate RMSE)\n",
    "rmse_scorer = make_scorer(lambda y_true, y_pred: -np.sqrt(mean_squared_error(y_true, y_pred)))\n",
    "\n",
    "\n",
    "\n",
    "xgb_param_grid = {\n",
    "    \"rfe__estimator__n_estimators\": [197],\n",
    "    \"rfe__estimator__max_depth\": [4],\n",
    "    \"rfe__estimator__learning_rate\": [0.059362936390648706],\n",
    "    \"rfe__estimator__reg_alpha\": [0.3243563176277785],\n",
    "    \"rfe__estimator__reg_lambda\": [5.0229339349076065],\n",
    "    \"rfe__n_features_to_select\": [49]\n",
    "}\n",
    "\n",
    "\n",
    "pipe = make_pipeline(\n",
    "    preprocessor,\n",
    "    RFE(estimator=XGBRegressor(random_state=42, verbosity=0), step=0.2)\n",
    ")\n",
    "\n",
    "\n",
    "xgb_search = GridSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_grid=xgb_param_grid,\n",
    "    scoring=rmse_scorer,\n",
    "    refit=True,\n",
    "    cv=2,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "xgb_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Best parameters:\", xgb_search.best_params_)\n",
    "print(\"Best RMSE (negative):\", xgb_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61c10aad-57a0-486d-8e27-f8035fd7c805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 1.0090\n",
      "Validation RMSE (CV): 1.0878\n",
      "Test RMSE: 1.0586\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Train RMSE\n",
    "# ----------------------------\n",
    "train_preds = xgb_search.predict(X_train)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, train_preds))\n",
    "print(f\"Train RMSE: {rmse_train:.4f}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Validation RMSE (from CV)\n",
    "# ----------------------------\n",
    "# Since we used negative RMSE as the scoring function\n",
    "rmse_val = -xgb_search.best_score_\n",
    "print(f\"Validation RMSE (CV): {rmse_val:.4f}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Test RMSE (on unseen data)\n",
    "# ----------------------------\n",
    "test_preds = xgb_search.predict(X_test)\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, test_preds))\n",
    "print(f\"Test RMSE: {rmse_test:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f1a72e-df8a-46c2-b65f-45acd875a13d",
   "metadata": {},
   "source": [
    "## Comparing Classification Models\n",
    "After experimenting with RandomForestClassifier, XGBClassifier, and LogisticRegression for our classification task (predicting ratings from 1 to 5), we evaluated their performance to determine the best model for this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "bb05aa1e-4d4a-436d-b38e-3ab393615fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\win-10\\.conda\\envs\\tf2\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [14:20:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\win-10\\.conda\\envs\\tf2\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [14:21:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\win-10\\.conda\\envs\\tf2\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [14:22:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\win-10\\.conda\\envs\\tf2\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [14:23:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\win-10\\.conda\\envs\\tf2\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [14:24:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\win-10\\.conda\\envs\\tf2\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [14:24:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'rfe__estimator__learning_rate': 0.059362936390648706, 'rfe__estimator__max_depth': 4, 'rfe__estimator__n_estimators': 197, 'rfe__estimator__reg_alpha': 0.3243563176277785, 'rfe__estimator__reg_lambda': 5.0229339349076065, 'rfe__n_features_to_select': 49}\n",
      "Best macro F1 score: 0.4145899583107882\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.441     0.624     0.517       426\n",
      "           1      0.384     0.264     0.313       394\n",
      "           2      0.431     0.291     0.347       409\n",
      "           3      0.400     0.415     0.408       390\n",
      "           4      0.551     0.643     0.593       381\n",
      "\n",
      "    accuracy                          0.448      2000\n",
      "   macro avg      0.441     0.448     0.436      2000\n",
      "weighted avg      0.441     0.448     0.435      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier  # Use classifier\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "# Define your preprocessor (missing in your snippet)\n",
    "# Example: preprocessor = ColumnTransformer([...])\n",
    "\n",
    "# Define a proper scorer\n",
    "f1_macro_scorer = make_scorer(f1_score, average='macro')\n",
    "\n",
    "pipe = make_pipeline(\n",
    "    preprocessor,\n",
    "    RFE(estimator=XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'), step=0.2)\n",
    ")\n",
    "\n",
    "xgb_param_grid = {\n",
    "    \"rfe__estimator__n_estimators\": [197],\n",
    "    \"rfe__estimator__max_depth\": [4],\n",
    "    \"rfe__estimator__learning_rate\": [0.059362936390648706],\n",
    "    \"rfe__estimator__reg_alpha\": [0.3243563176277785],\n",
    "    \"rfe__estimator__reg_lambda\": [5.0229339349076065],\n",
    "    \"rfe__n_features_to_select\": [49]\n",
    "}\n",
    "\n",
    "xgb_search = GridSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_grid=xgb_param_grid,\n",
    "    scoring=f1_macro_scorer,\n",
    "    refit=True,\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "xgb_search.fit(X_train, y_train)\n",
    "y_pred = xgb_search.predict(X_test)\n",
    "\n",
    "print(\"Best parameters:\", xgb_search.best_params_)\n",
    "print(\"Best macro F1 score:\", xgb_search.best_score_)\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred, digits=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "19e1479c-8482-4a3c-b967-ba6ec31e2c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Best parameters: {'rfe__estimator__max_depth': 4, 'rfe__estimator__n_estimators': 197, 'rfe__n_features_to_select': 49}\n",
      "Best macro F1 score: 0.36130793661590616\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.368     0.646     0.468       426\n",
      "           1      0.363     0.277     0.314       394\n",
      "           2      0.429     0.264     0.327       409\n",
      "           3      0.398     0.231     0.292       390\n",
      "           4      0.489     0.609     0.543       381\n",
      "\n",
      "    accuracy                          0.407      2000\n",
      "   macro avg      0.409     0.405     0.389      2000\n",
      "weighted avg      0.408     0.407     0.389      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define your preprocessor (make sure this is defined somewhere in your code)\n",
    "# e.g., preprocessor = ColumnTransformer([...])\n",
    "\n",
    "# Define the scoring metric\n",
    "f1_macro_scorer = make_scorer(f1_score, average='macro')\n",
    "\n",
    "pipe = make_pipeline(\n",
    "    preprocessor,\n",
    "    RFE(estimator=RandomForestClassifier(random_state=42), step=0.2)\n",
    ")\n",
    "\n",
    "# Parameter grid for RandomForest inside RFE\n",
    "rf_param_grid = {\n",
    "    \"rfe__estimator__n_estimators\": [197],\n",
    "    \"rfe__estimator__max_depth\": [4],\n",
    "    # RandomForest doesn't have learning_rate, reg_alpha, reg_lambda\n",
    "    \"rfe__n_features_to_select\": [49]\n",
    "}\n",
    "\n",
    "rf_search = GridSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_grid=rf_param_grid,\n",
    "    scoring=f1_macro_scorer,\n",
    "    refit=True,\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "rf_search.fit(X_train, y_train)\n",
    "y_pred = rf_search.predict(X_test)\n",
    "\n",
    "print(\"Best parameters:\", rf_search.best_params_)\n",
    "print(\"Best macro F1 score:\", rf_search.best_score_)\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred, digits=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872f1cac-b753-4fec-9aae-07d87b5153d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "Best parameters: {'logisticregression__C': 1.0, 'logisticregression__penalty': 'l1', 'logisticregression__solver': 'saga'}\n",
      "Best macro F1 score (CV): 0.4408638795394544\n",
      "Test Accuracy: 0.473\n",
      "\n",
      "Classification Report on Test Set:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.489     0.617     0.546       426\n",
      "           1      0.422     0.327     0.369       394\n",
      "           2      0.433     0.330     0.374       409\n",
      "           3      0.446     0.426     0.436       390\n",
      "           4      0.536     0.664     0.593       381\n",
      "\n",
      "    accuracy                          0.473      2000\n",
      "   macro avg      0.465     0.473     0.464      2000\n",
      "weighted avg      0.465     0.473     0.463      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import make_scorer, f1_score, accuracy_score, classification_report\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# Assume `preprocessor`, `X_train`, `y_train`, `X_test`, `y_test` are already defined\n",
    "\n",
    "# Define scoring metric\n",
    "f1_macro_scorer = make_scorer(f1_score, average='macro')\n",
    "\n",
    "# Define pipeline with preprocessing and univariate feature selection\n",
    "pipe = make_pipeline(\n",
    "    preprocessor,\n",
    "    SelectKBest(score_func=f_classif, k=70),  # Pre-select top features\n",
    "    LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        random_state=42,\n",
    "        class_weight='balanced'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Hyperparameter grid for logistic regression\n",
    "logreg_param_grid = {\n",
    "    \"logisticregression__C\": [0.01, 0.1, 1.0],  # Regularization strength\n",
    "    \"logisticregression__solver\": ['liblinear', 'saga'],\n",
    "    \"logisticregression__penalty\": ['l2', 'l1']  # Note: 'l1' only works with 'liblinear' or 'saga'\n",
    "}\n",
    "\n",
    "# Grid search\n",
    "logreg_search = GridSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_grid=logreg_param_grid,\n",
    "    scoring=f1_macro_scorer,\n",
    "    refit=True,\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Fit model\n",
    "logreg_search.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = logreg_search.predict(X_test)\n",
    "\n",
    "print(\"Best parameters:\", logreg_search.best_params_)\n",
    "print(\"Best macro F1 score (CV):\", logreg_search.best_score_)\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report on Test Set:\\n\")\n",
    "print(classification_report(y_test, y_pred, digits=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee77e672-ef3a-44a1-b93f-162576ebb854",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2be6402-6df8-40f1-a861-d0efbb498e3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b2e552-95a5-475b-87b4-5e462cd94248",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caf7ef2-8183-4711-a1ff-b042a2dc723b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc6e9d4-a0fa-4cdc-bf1b-d0ca9360314d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52db0565-4c1d-4bbc-9d70-63b9a92d4af8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df12298-0a03-4f84-8acb-92f90d90b941",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac2eec0-25fd-4cb5-b1db-94a555726d36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936295b2-c17e-4e65-a23c-8121fda8df65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4411ce8-5638-48ee-9079-9ce3e59fd9e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3054272e-c6d1-4b05-96aa-7bfb8bc171b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84751ac9-2a98-46db-a34c-23e537d2a5bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9a4c75-2321-436a-be88-326b232d8952",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee6ee26-7cd8-4e11-8bbd-8c79c63714d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b126c73e-72d8-4685-837a-443505070514",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ddbb0d-cf8a-48fe-aa01-2631a1f0d0fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3966f207-44a7-4f02-b24e-4baabca0f9b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3130a0d4-2be3-4623-9ae3-2c1d2c853326",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa98460-066f-48e9-8e29-b924bf756804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fdc110-8e28-4207-a140-2004ea4dbcb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf2)",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
